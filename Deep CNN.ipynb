{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "import sys\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#from tqdm import tqdm_notebook\n",
    "from notifyme import notify\n",
    "from gc import collect\n",
    "from time import time,sleep\n",
    "from os import path,system\n",
    "from json import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id               200840\n",
       "grapheme_root             168\n",
       "vowel_diacritic            11\n",
       "consonant_diacritic         7\n",
       "grapheme                 1295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.uint16'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grapheme_root_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "vowel_diacritic_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "consonant_diacritic_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "\n",
    "grapheme_root_ohe.fit(labels[['grapheme_root']])\n",
    "vowel_diacritic_ohe.fit(labels[['vowel_diacritic']])\n",
    "consonant_diacritic_ohe.fit(labels[['consonant_diacritic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inputs = Input(shape = (48, 48, 1),name=\"inputs\")\n",
    "# model = Conv2D(filters=32, kernel_size=(4, 4), padding='SAME', activation='relu', input_shape=(48,48,1))(inputs)\n",
    "# model = Conv2D(filters=32, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "# model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "# model = Dropout(rate=0.3)(model)\n",
    "\n",
    "# model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "# model = Conv2D(filters=64, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "# model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = Dropout(rate=0.3)(model)\n",
    "\n",
    "# model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "# model = Conv2D(filters=128, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "# model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = Dropout(rate=0.3)(model)\n",
    "\n",
    "# model = Conv2D(filters=256, kernel_size=(6, 6), padding='SAME', activation='relu')(model)\n",
    "# model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "# model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "# model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "# model = BatchNormalization(momentum=0.15)(model)\n",
    "# model = Dropout(rate=0.3)(model)\n",
    "\n",
    "# model = Flatten()(model)\n",
    "# model = Dense(1024, activation = \"relu\")(model)\n",
    "# model = Dropout(rate=0.3)(model)\n",
    "# dense = Dense(512, activation = \"relu\")(model)\n",
    "\n",
    "# head_root = Dense(168, activation = 'softmax',name=\"grapheme_root\")(dense)\n",
    "# head_vowel = Dense(11, activation = 'softmax',name='vowel_diacritic')(dense)\n",
    "# head_consonant = Dense(7, activation = 'softmax',name='consonant_diacritic')(dense)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (48, 48, 1),name=\"inputs\")\n",
    "model = Conv2D(filters=32, kernel_size=(8, 8), padding='SAME', activation='relu', input_shape=(48,48,1))(inputs)\n",
    "model = Conv2D(filters=32, kernel_size=(6, 6), padding='SAME', activation='relu')(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=64, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "model = Dense(4096, activation = \"relu\")(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(1024, activation = \"relu\")(model)\n",
    "\n",
    "head_root = Dense(168, activation = 'softmax',name=\"grapheme_root\")(dense)\n",
    "head_vowel = Dense(11, activation = 'softmax',name='vowel_diacritic')(dense)\n",
    "head_consonant = Dense(7, activation = 'softmax',name='consonant_diacritic')(dense)\n",
    "\n",
    "outputs = [\n",
    "        head_root, \n",
    "#         head_vowel, \n",
    "#         head_consonant\n",
    "]\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop(img,pad=True):\n",
    "    W_THRESH = 8\n",
    "    H_THRESH = 8\n",
    "    PAD = 3 if pad else 0\n",
    "\n",
    "    W_MIN,W_MAX = np.where(img.std(axis=0) > W_THRESH)[0][[0,-1]]\n",
    "    H_MIN,H_MAX = np.where(img.std(axis=1) > H_THRESH)[0][[0,-1]]\n",
    "    \n",
    "    return np.pad(img[H_MIN:H_MAX,W_MIN:W_MAX],PAD,constant_values=253)\n",
    "\n",
    "def resize(img):\n",
    "    img = crop(img.reshape(137,236).astype(np.uint8))\n",
    "    ret,img = cv.threshold(img,110,255,cv.THRESH_BINARY_INV)    \n",
    "    return cv.resize(img,(48,48)).astype(np.uint8).reshape(48,48,1)\n",
    "\n",
    "def input_flow(x,y,batch_size=200,epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(batch_size,x.shape[0],batch_size):\n",
    "            rows = x.iloc[i-batch_size:i].values\n",
    "            yield (\n",
    "                    {\n",
    "                        \"inputs\":np.apply_along_axis(resize,axis=1,arr=rows)/255\n",
    "                    },\n",
    "                    {\n",
    "                        \"grapheme_root\":y[0][i-batch_size:i],\n",
    "                        'vowel_diacritic':y[1][i-batch_size:i],\n",
    "                        'consonant_diacritic':y[2][i-batch_size:i]\n",
    "                    }\n",
    "                )\n",
    "        rows = x.iloc[i:].values\n",
    "        yield (\n",
    "                    {\n",
    "                        \"inputs\":np.apply_along_axis(resize,axis=1,arr=rows)/255\n",
    "                    },\n",
    "                    {\n",
    "                        \"grapheme_root\":y[0][i:],\n",
    "                        'vowel_diacritic':y[1][i:],\n",
    "                        'consonant_diacritic':y[2][i:]\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(file_id):\n",
    "    df = pd.merge(\n",
    "            pd.read_parquet(f\"./train_image_data_{file_id}.parquet\"),\n",
    "            labels,\n",
    "            on='image_id'\n",
    "        )\n",
    "    \n",
    "    grapheme_root = grapheme_root_ohe.transform(df.grapheme_root.values.reshape(-1,1))\n",
    "    vowel_diacritic = vowel_diacritic_ohe.transform(df.vowel_diacritic.values.reshape(-1,1))\n",
    "    consonant_diacritic = consonant_diacritic_ohe.transform(df.consonant_diacritic.values.reshape(-1,1))\n",
    "    \n",
    "    df = df.drop(columns=['image_id','grapheme_root','vowel_diacritic','consonant_diacritic','grapheme'])\n",
    "    \n",
    "    return df,(grapheme_root,vowel_diacritic,consonant_diacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \".keras_checkpoints/chek.ckpt\"\n",
    "checkpoint_dir = path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 10\n",
    "SUB_EPOCHS = 2\n",
    "START_EPOCH = 0\n",
    "\n",
    "HALT = True\n",
    "\n",
    "# if RESUME:\n",
    "#     log = open(\"./log.txt\",'r').read().split(\" \")\n",
    "#     START_EPOCH = int(log[2])\n",
    "\n",
    "#     latest = tf.train.latest_checkpoint(\"./.keras_checkpoints\")\n",
    "#     model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | FILE : 0\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 52s 412ms/step - loss: 4.3200 - accuracy: 0.0738\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 50s 400ms/step - loss: 2.6148 - accuracy: 0.3324\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 47s 373ms/step - loss: 1.5074 - accuracy: 0.5800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c7f7a0228068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHALT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"EPOCH : {epoch} | FILE : {file_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH,EPOCHS):\n",
    "    hist = None\n",
    "    for file_id in range(4):\n",
    "        print (f\"EPOCH : {epoch} | FILE : {file_id}\")\n",
    "        X,Y = get_train_test(file_id)\n",
    "        gen = input_flow(X,Y,batch_size=BATCH_SIZE,epochs=SUB_EPOCHS)\n",
    "        \n",
    "        model.fit_generator(gen,steps_per_epoch=X.shape[0]//BATCH_SIZE,epochs=SUB_EPOCHS)\n",
    "\n",
    "        del X,Y\n",
    "        collect()\n",
    "        if HALT:\n",
    "            sleep(90)\n",
    "    \n",
    "        open(\"./log.txt\",\"w+\").write(f\"EPOCH : {epoch} | FILE : {file_id}\")\n",
    "\n",
    "    \n",
    "model.save_weights(\"./.weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
