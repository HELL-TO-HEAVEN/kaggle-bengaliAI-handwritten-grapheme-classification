{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from notifyme import notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapheme_root_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "vowel_diacritic_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "consonant_diacritic_ohe = OneHotEncoder(dtype=np.uint16,sparse=False)\n",
    "\n",
    "grapheme_root_ohe.fit(labels[['grapheme_root']])\n",
    "vowel_diacritic_ohe.fit(labels[['vowel_diacritic']])\n",
    "consonant_diacritic_ohe.fit(labels[['consonant_diacritic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./train_image_data_0.parquet\")\n",
    "df = pd.merge(df,labels,on='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape = (SHAPE_NEW, SHAPE_NEW, 1),name=\"input\")\n",
    "model = Conv2D(filters=32, kernel_size=(4, 4), padding='SAME', activation='relu', input_shape=(SHAPE_NEW, SHAPE_NEW, 1))(inputs)\n",
    "model = Conv2D(filters=32, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(4, 4), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(6, 6), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "model = Dense(1024, activation = \"relu\")(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(512, activation = \"relu\")(model)\n",
    "\n",
    "head_root = Dense(168, activation = 'softmax',name=\"grapheme_root\")(dense)\n",
    "head_vowel = Dense(11, activation = 'softmax',name='vowel_diacritic')(dense)\n",
    "head_consonant = Dense(7, activation = 'softmax',name='consonant_diacritic')(dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (137,236)\n",
    "SHAPE_NEW = 48\n",
    "KERNEL = np.ones((2,2),np.float32)/25\n",
    "\n",
    "def crop(img,pad=True):\n",
    "    W_THRESH = 8\n",
    "    H_THRESH = 8\n",
    "    PAD = 3 if pad else 0\n",
    "\n",
    "    W_MIN,W_MAX = np.where(img.std(axis=0) > W_THRESH)[0][[0,-1]]\n",
    "    H_MIN,H_MAX = np.where(img.std(axis=1) > H_THRESH)[0][[0,-1]]\n",
    "    \n",
    "    return np.pad(img[H_MIN:H_MAX,W_MIN:W_MAX],PAD,constant_values=253)\n",
    "\n",
    "def resize(img,shape_=SHAPE_NEW,crop_=True,inv_=True):\n",
    "    \n",
    "    if crop_:\n",
    "        img = crop(img.reshape(SHAPE).astype(np.uint8))\n",
    "    if inv_:\n",
    "        ret,img = cv.threshold(img,110,255,cv.THRESH_BINARY_INV)\n",
    "        \n",
    "    return cv.resize(img,(shape_,shape_)).astype(np.uint8)\n",
    "\n",
    "def input_flow(X,sharpen=1):\n",
    "    for i in range(X.shape[0]):\n",
    "        row = X.iloc[i].values\n",
    "        yield ({\n",
    "                'input':resize(row[1:-4]).reshape(1,SHAPE_NEW,SHAPE_NEW,1)/255\n",
    "            },\n",
    "            {\n",
    "                'grapheme_root':grapheme_root_ohe.transform([row[-4:-3]]),\n",
    "                'vowel_diacritic':vowel_diacritic_ohe.transform([row[-3:-2]]),\n",
    "                'consonant_diacritic':consonant_diacritic_ohe.transform([row[-2:-1]])\n",
    "            }\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "img = df.iloc[80][1:-4].values\n",
    "fig,axes = plt.subplots(1,4,figsize=(10,4))\n",
    "axes[0].imshow(img.astype(int).reshape(SHAPE),cmap='gray')\n",
    "axes[1].imshow(resize(img,shape_=128),cmap='gray')\n",
    "axes[2].imshow(resize(img,shape_=64),cmap='gray')\n",
    "axes[3].imshow(resize(img,shape_=32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(input_flow(df),steps_per_epoch=df.shape[0], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
